{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myname = \"Ritesh-Gupta-\"\n",
    "#features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('dataset/spam_data.txt', 'r')\n",
    "data = []\n",
    "for line in f.readlines():\n",
    "    r = []\n",
    "    for word in line.split():\n",
    "        r.append(word)\n",
    "    data.append(r)\n",
    "f.close()\n",
    "data = np.asarray(data)\n",
    "data = data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3220, 58)\n"
     ]
    }
   ],
   "source": [
    "length = len(data)\n",
    "train_data = data[:int(0.7*length),:]\n",
    "test_data = data[int(0.7*length):,:]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1381, 57)\n",
      "[[0.000e+00 6.400e-01 6.400e-01 ... 6.100e+01 2.780e+02 1.000e+00]\n",
      " [2.100e-01 2.800e-01 5.000e-01 ... 1.010e+02 1.028e+03 1.000e+00]\n",
      " [6.000e-02 0.000e+00 7.100e-01 ... 4.850e+02 2.259e+03 1.000e+00]\n",
      " ...\n",
      " [0.000e+00 4.300e-01 4.300e-01 ... 6.100e+01 2.220e+02 1.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 1.700e+01 1.910e+02 1.000e+00]\n",
      " [1.240e+00 4.100e-01 1.240e+00 ... 1.900e+01 1.140e+02 1.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "X_test = test_data[:,:-1]\n",
    "y_test = test_data[:,-1]\n",
    "print(X_test.shape)\n",
    "X_tr = train_data[:100,:]\n",
    "print(X_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Unique Element and its count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_count_dict(col):\n",
    "    unique_elements, counts_elements = np.unique(col, return_counts=True)\n",
    "    return dict(zip(unique_elements,counts_elements))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy function e = sum(-p*log2(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    return -np.sum(np.multiply(p,np.log2(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impurity(rows):\n",
    "    count=unique_count_dict(rows[:,-1])\n",
    "    p = []\n",
    "    for label in count:\n",
    "        p.append(count[label]/float(len(rows)))\n",
    "    #return gini(p)\n",
    "    return entropy(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gini Impurity g = 1- sum(pi^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(prob):\n",
    "    impurity=1\n",
    "    return (1 - np.sum(np.power(prob,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Gain of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain_entropy(current,left,right):\n",
    "    p =float(len(left))/len(left)+len(right)\n",
    "    left = np.asarray(left)\n",
    "    right = np.asarray(right)\n",
    "    return current-p*impurity(left)-(1-p)*impurity(right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    def __init__(self,column,value):\n",
    "        self.column=column\n",
    "        self.value=value\n",
    "    def match(self,data):\n",
    "        value=data[self.column]\n",
    "        return value>=self.value\n",
    "    def __repr__(self):\n",
    "        condition = \">=\"\n",
    "        return \"Is %s %s %s?\" % (features[self.column], condition, str(self.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition column based of question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data,val,col):\n",
    "    true_row,false_row=[],[]\n",
    "    for row in data:\n",
    "        if row[col] >= val:\n",
    "            true_row.append(row)\n",
    "        else:\n",
    "            false_row.append(row)\n",
    "    true_row  = np.asarray(true_row)\n",
    "    false_row = np.asarray(false_row) \n",
    "    return true_row,false_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate best gain and Split of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(rows):\n",
    "    best_gain=0\n",
    "    best_question=None\n",
    "    value = 0\n",
    "    column = 0\n",
    "    current=impurity(rows)\n",
    "    features=len(rows[0])-1\n",
    "    for col in range(features):\n",
    "        val = np.average(rows[:,col])\n",
    "        question = Question(col,val)\n",
    "        true_rows,false_rows = split(rows,val,col)\n",
    "        if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "            continue\n",
    "        gain=info_gain_entropy(current,true_rows,false_rows)\n",
    "        if gain>=best_gain:\n",
    "                best_gain,best_question,value,column=gain,question,val,col\n",
    "    return best_gain,best_question,value,column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class to store decision Node i.e. question of split left and right branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self,question,true_branch,false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Leaf instance with % of occurence of label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self,rows):\n",
    "        count = unique_count_dict(rows[:,-1])\n",
    "        p = {}\n",
    "        for label in count:\n",
    "            p[label] = count[label]/float(len(rows))\n",
    "        self.dict = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building tree recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(rows):\n",
    "    gain,ques,val,col=best_split(rows)\n",
    "    if gain==0:\n",
    "        return Leaf(rows)\n",
    "    true_rows, false_rows = split(rows,val,col)\n",
    "    true_branch = build_tree(true_rows)\n",
    "    false_branch = build_tree(false_rows)\n",
    "    return DecisionNode(ques,true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the predicted Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row, node):\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.dict\n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(result,c):\n",
    "    pred_label = []\n",
    "    max1 = 0\n",
    "    max2 = 0\n",
    "    val = 0\n",
    "    for i in range(len(result)):\n",
    "        d = 0.0\n",
    "        if len(result[i]) == 2: \n",
    "            for k,v in result[i].items():\n",
    "                #max1 = int(v.replace(\"%\",\"\"))\n",
    "                max1 = int(v)\n",
    "                d = k\n",
    "                if max1 > max2:\n",
    "                    d = k\n",
    "        else:\n",
    "            for k,v in result[i].items():\n",
    "                d = k\n",
    "        pred_label.append(d)\n",
    "    pred_label = np.asarray(pred_label)\n",
    "    count = 0\n",
    "    for i in range(len(c)):\n",
    "        if c[i] == pred_label[i]:\n",
    "            count +=1\n",
    "    return (count/len(c)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest():\n",
    "    total_feature = train_data.shape[1]-1\n",
    "    no_of_itr = 10\n",
    "    acc = []\n",
    "    total_tree = []\n",
    "    for itr in range(no_of_itr):\n",
    "        rand = np.arange(total_feature)\n",
    "        np.random.shuffle(rand)\n",
    "        features_to_train = 25\n",
    "        sample = 100\n",
    "        np.random.shuffle(train_data)\n",
    "        X_train = []\n",
    "        X_train = np.asarray(X_train)\n",
    "        X_train = train_data[:,rand[0]]\n",
    "        for i in range(1,features_to_train):\n",
    "            X_train = np.column_stack((X_train,train_data[:,rand[i]]))\n",
    "        X_train = np.column_stack((X_train,train_data[:,-1]))\n",
    "        X_tr = X_train[:sample,:]\n",
    "        tree = build_tree(X_train)\n",
    "        total_tree.append(tree)\n",
    "        result = []\n",
    "        for i in range(len(X_test)):\n",
    "            result.append(classify(X_test[i], tree))\n",
    "        res = accuracy(result,y_test)\n",
    "        print(res)\n",
    "        acc.append(res)\n",
    "    acc = np.asarray(acc)\n",
    "    return np.max(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.15278783490224\n",
      "23.533671252715425\n",
      "52.78783490224475\n",
      "56.55322230267922\n",
      "65.38740043446778\n",
      "51.04996379435192\n",
      "43.95365677045619\n",
      "59.81173062997828\n",
      "33.1643736422882\n",
      "55.17740767559739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69.15278783490224"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7aa2eb5277d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_decision_tree_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = build_tree(train_data)\n",
    "result = []\n",
    "for i in range(len(X_test)):\n",
    "    result.append(classify(X_test[i], tree))\n",
    "accuracy(result,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
